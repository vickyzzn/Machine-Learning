{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Linear Regression\n",
    "\n",
    "LR is a widely used model that is efficient, easy to train and interpretatble. We will use <span style=\"font-family:Comic Sans MS\">sk-learn</span> and a couple of modules from <span style=\"font-family:Comic Sans MS\">statsmodels</span> to demo the working of an LR model.\n",
    "\n",
    "https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essetial imports\n",
    "\n",
    "# This line enables inline plots within jupyter notebook\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HoursStudied</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.502345</td>\n",
       "      <td>31.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.426804</td>\n",
       "      <td>68.777596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.530358</td>\n",
       "      <td>62.562382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.475640</td>\n",
       "      <td>71.546632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.813208</td>\n",
       "      <td>87.230925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HoursStudied      Score\n",
       "0     32.502345  31.707006\n",
       "1     53.426804  68.777596\n",
       "2     61.530358  62.562382\n",
       "3     47.475640  71.546632\n",
       "4     59.813208  87.230925"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data/data.csv', delimiter='\\t', header=None)\n",
    "df.columns = ['HoursStudied', 'Score'] # 'Score' is our target variable.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/seaborn/axisgrid.py:2065: UserWarning: The `size` parameter has been renamed to `height`; pleaes update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x10c9ad7f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at the scatter plot\n",
    "sns.pairplot(data=df, x_vars=['HoursStudied'], y_vars='Score', kind='reg', size=6, aspect=1.5) # in latest sns use 'height' \n",
    "                                                                                   # in place of  'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'HoursStudied')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['HoursStudied'], df['Score'])\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('HoursStudied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for splitting data into train and test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['HoursStudied']]\n",
    "y = df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=0.25)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. By default, the value is set to 0.25.\n",
      "        The default will change in version 0.21. It will remain 0.25 only\n",
      "        if ``train_size`` is unspecified, otherwise it will complement\n",
      "        the specified ``train_size``.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using train_test_split get our sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train['HoursStudied'], y_train)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('HoursStudied')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the plot above, we notice that there are some outliers and leverage points\n",
    "# Outliers: An outlier is a point i for which y_i is far from the value predicted by the model.\n",
    "# Leverage: Point i with high leverage has an unusual value for x_i\n",
    "# Here you'll find a pictorial explanation of this concept https://newonlinecourses.science.psu.edu/stat501/node/337/\n",
    "\n",
    "#In the next couple of steps we'll fit a regression model and study the residual plot to understand outliers better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LR model class\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using training set\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  30.202307422099224\n",
      "Slope:  [0.77403028]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the parameters that we learned\n",
    "print('Intercept: ', lr.intercept_)\n",
    "print('Slope: ', lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# residual vs predicted values: on training set\n",
    "pred_vals = lr.predict(X_train)\n",
    "residuals = pred_vals - y_train\n",
    "plt.scatter(pred_vals, residuals)\n",
    "plt.hlines(y=0, xmin=60, xmax=80)\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29136.8309389517"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual Sum of Squares\n",
    "(residuals**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\"\n",
    "     Linear Regression(Linear Least Squares Regression).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "        self.std_scaler = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the regression model to the training data.\n",
    "\n",
    "        Arguments\n",
    "        ----------\n",
    "        X: nxp matrix of n examples with p independent variables\n",
    "        y: response variable vector for n examples\n",
    "        \"\"\"\n",
    "        X = np.hstack([np.ones(X.shape[0]).reshape(X.shape[0],1), X])\n",
    "        self.beta = np.dot(np.linalg.inv(np.dot(X.T, X)),\n",
    "                             np.dot(X.T, y))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the dependent variable of new data using the model.\n",
    "        Arguments\n",
    "        ----------\n",
    "        X: nxp matrix of n examples with p covariates\n",
    "        Returns\n",
    "        ----------\n",
    "        response variable vector for n examples\n",
    "        \"\"\"\n",
    "        X = np.hstack([np.ones(X.shape[0]).reshape(X.shape[0],1), X])\n",
    "        return np.dot(X, self.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.21889661,  0.5752331 ])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using our own hand-crafted model\n",
    "model = Model()\n",
    "model.fit(X_train, y_train)\n",
    "model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101    False\n",
      "64      True\n",
      "111    False\n",
      "3       True\n",
      "47      True\n",
      "88      True\n",
      "82      True\n",
      "109    False\n",
      "69      True\n",
      "34      True\n",
      "Name: Score, dtype: bool 101   -33.841969\n",
      "64     -5.820508\n",
      "111    45.847366\n",
      "3      -2.496792\n",
      "47    -16.752550\n",
      "88     -5.810729\n",
      "82      8.603094\n",
      "109    20.847366\n",
      "69     12.088213\n",
      "34     -1.430060\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's remove the points with high reisdual values\n",
    "mask = ~(abs(residuals) > 20)\n",
    "print(mask[:10], residuals[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train[mask],y_train[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFXCAYAAABZQMyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca97550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# residual vs predicted values: on training set\n",
    "pred_vals = lr.predict(X_train[mask])\n",
    "residuals = pred_vals - y_train[mask]\n",
    "plt.scatter(pred_vals, residuals)\n",
    "plt.hlines(y=0, xmin=60, xmax=80)\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5918.79043961122"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(residuals**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubhranshu.shekhar/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:601: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HoursStudied</th>\n",
       "      <th>duplicate_HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>35.128485</td>\n",
       "      <td>35.128485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33.644706</td>\n",
       "      <td>33.644706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>68.765734</td>\n",
       "      <td>68.765734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.475640</td>\n",
       "      <td>47.475640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>53.575078</td>\n",
       "      <td>53.575078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HoursStudied  duplicate_HS\n",
       "101     35.128485     35.128485\n",
       "64      33.644706     33.644706\n",
       "111     68.765734     68.765734\n",
       "3       47.475640     47.475640\n",
       "47      53.575078     53.575078"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's introduce perfect collinearity into the data\n",
    "X_train.loc[:, 'duplicate_HS'] = X_train['HoursStudied']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAFYCAYAAADTHn7RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDwJIcQKVDwJIcQK/x8tw0opIWdzeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7df748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To find out collinearity between two variables we could take a look at paiwise scatter plot\n",
    "g = sns.pairplot(data=X_train, diag_kind=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# However scatter plots will not be able to detect multi-collinearity. However, we can systematically address this \n",
    "# using HIF values. Source: https://www.kaggle.com/ffisegydd/sklearn-multicollinearity-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for VIF score claculation\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import Imputer # for imputing missing values\n",
    "\n",
    "# imports for creating custom sklearn transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=5.0, impute=True, impute_strategy='median'):\n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "        if impute:\n",
    "            self.imputer = Imputer(strategy=impute_strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('ReduceVIF fit')\n",
    "        if hasattr(self, 'imputer'):\n",
    "            self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print('ReduceVIF transform')\n",
    "        columns = X.columns.tolist()\n",
    "        if hasattr(self, 'imputer'):\n",
    "            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh=5.0):\n",
    "        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            variables = X.columns\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll demomstrate this using Boston housing dataset\n",
    "# Let's start with data loading\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  36.49110328036199\n",
      "Weights: \n",
      "[('CRIM', -0.10717055656035383), ('ZN', 0.046395219529801815), ('INDUS', 0.020860239532171893), ('CHAS', 2.6885613993179547), ('NOX', -17.79575866030902), ('RM', 3.804752460258001), ('AGE', 0.0007510617033206213), ('DIS', -1.4757587965198176), ('RAD', 0.30565503833909746), ('TAX', -0.012329346305271827), ('PTRATIO', -0.9534635546905583), ('B', 0.009392512722189217), ('LSTAT', -0.5254666329007893)]\n"
     ]
    }
   ],
   "source": [
    "# Fit LR before removing any columns\n",
    "lr_c = LinearRegression()\n",
    "lr_c.fit(X, y)\n",
    "print('Intercept: ', lr_c.intercept_)\n",
    "print('Weights: ') \n",
    "print([(k, v) for k, v in zip(X.columns, lr_c.coef_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReduceVIF fit\n",
      "ReduceVIF transform\n",
      "Dropping PTRATIO with vif=85.02731352042679\n",
      "Dropping NOX with vif=73.90144446644008\n",
      "Dropping TAX with vif=57.720177047564796\n",
      "Dropping RM with vif=39.055353678044725\n",
      "Dropping AGE with vif=14.000157151747949\n",
      "Dropping B with vif=10.057375463850262\n",
      "Dropping INDUS with vif=6.8965944324236315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_collinearity = ReduceVIF()\n",
    "X_new = remove_collinearity.fit_transform(X, y)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  39.189111927805584\n",
      "Weights: \n",
      "[('CRIM', -0.09972583004187899), ('ZN', 0.09722051088181435), ('CHAS', 3.952836121583388), ('DIS', -1.4134746978173844), ('RAD', -0.055709992589870264), ('LSTAT', -0.9309932657793781)]\n"
     ]
    }
   ],
   "source": [
    "# Fit again\n",
    "lr_c = LinearRegression()\n",
    "lr_c.fit(X_new, y)\n",
    "print('Intercept: ', lr_c.intercept_)\n",
    "print('Weights: ') \n",
    "print([(k, v) for k, v in zip(X_new.columns, lr_c.coef_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularization\n",
    "from sklearn.linear_model import Ridge #L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Ridge in module sklearn.linear_model.ridge:\n",
      "\n",
      "class Ridge(_BaseRidge, sklearn.base.RegressorMixin)\n",
      " |  Linear least squares with l2 regularization.\n",
      " |  \n",
      " |  This model solves a regression model where the loss function is\n",
      " |  the linear least squares function and regularization is given by\n",
      " |  the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      " |  This estimator has built-in support for multi-variate regression\n",
      " |  (i.e., when y is a 2d-array of shape [n_samples, n_targets]).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : {float, array-like}, shape (n_targets)\n",
      " |      Regularization strength; must be a positive float. Regularization\n",
      " |      improves the conditioning of the problem and reduces the variance of\n",
      " |      the estimates. Larger values specify stronger regularization.\n",
      " |      Alpha corresponds to ``C^-1`` in other linear models such as\n",
      " |      LogisticRegression or LinearSVC. If an array is passed, penalties are\n",
      " |      assumed to be specific to the targets. Hence they must correspond in\n",
      " |      number.\n",
      " |  \n",
      " |  fit_intercept : boolean\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, optional\n",
      " |      Maximum number of iterations for conjugate gradient solver.\n",
      " |      For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      " |      by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      " |  \n",
      " |  tol : float\n",
      " |      Precision of the solution.\n",
      " |  \n",
      " |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'}\n",
      " |      Solver to use in the computational routines:\n",
      " |  \n",
      " |      - 'auto' chooses the solver automatically based on the type of data.\n",
      " |  \n",
      " |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      " |        coefficients. More stable for singular matrices than\n",
      " |        'cholesky'.\n",
      " |  \n",
      " |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      " |        obtain a closed-form solution.\n",
      " |  \n",
      " |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      " |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      " |        more appropriate than 'cholesky' for large-scale data\n",
      " |        (possibility to set `tol` and `max_iter`).\n",
      " |  \n",
      " |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      " |        scipy.sparse.linalg.lsqr. It is the fastest but may not be available\n",
      " |        in old scipy versions. It also uses an iterative procedure.\n",
      " |  \n",
      " |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      " |        its improved, unbiased version named SAGA. Both methods also use an\n",
      " |        iterative procedure, and are often faster than other solvers when\n",
      " |        both n_samples and n_features are large. Note that 'sag' and\n",
      " |        'saga' fast convergence is only guaranteed on features with\n",
      " |        approximately the same scale. You can preprocess the data with a\n",
      " |        scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      All last five solvers support both dense and sparse data. However,\n",
      " |      only 'sag' and 'saga' supports sparse input when `fit_intercept` is\n",
      " |      True.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag'.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *random_state* to support Stochastic Average Gradient.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features,) or (n_targets, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : float | array, shape = (n_targets,)\n",
      " |      Independent term in decision function. Set to 0.0 if\n",
      " |      ``fit_intercept = False``.\n",
      " |  \n",
      " |  n_iter_ : array or None, shape (n_targets,)\n",
      " |      Actual number of iterations for each target. Available only for\n",
      " |      sag and lsqr solvers. Other solvers will return None.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RidgeClassifier, RidgeCV, :class:`sklearn.kernel_ridge.KernelRidge`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import Ridge\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> np.random.seed(0)\n",
      " |  >>> y = np.random.randn(n_samples)\n",
      " |  >>> X = np.random.randn(n_samples, n_features)\n",
      " |  >>> clf = Ridge(alpha=1.0)\n",
      " |  >>> clf.fit(X, y) # doctest: +NORMALIZE_WHITESPACE\n",
      " |  Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      " |        normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Ridge\n",
      " |      _BaseRidge\n",
      " |      abc.NewBase\n",
      " |      sklearn.linear_model.base.LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Ridge regression model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_targets]\n",
      " |          Target values\n",
      " |      \n",
      " |      sample_weight : float or numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso #L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Lasso in module sklearn.linear_model.coordinate_descent:\n",
      "\n",
      "class Lasso(ElasticNet)\n",
      " |  Linear Model trained with L1 prior as regularizer (aka the Lasso)\n",
      " |  \n",
      " |  The optimization objective for Lasso is::\n",
      " |  \n",
      " |      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      " |  \n",
      " |  Technically the Lasso model is optimizing the same objective function as\n",
      " |  the Elastic Net with ``l1_ratio=1.0`` (no L2 penalty).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <lasso>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, optional\n",
      " |      Constant that multiplies the L1 term. Defaults to 1.0.\n",
      " |      ``alpha = 0`` is equivalent to an ordinary least square, solved\n",
      " |      by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  fit_intercept : boolean\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  precompute : True | False | array-like, default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |      matrix can also be passed as argument. For sparse input\n",
      " |      this option is always ``True`` to preserve sparsity.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  max_iter : int, optional\n",
      " |      The maximum number of iterations\n",
      " |  \n",
      " |  tol : float, optional\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``.\n",
      " |  \n",
      " |  warm_start : bool, optional\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |  \n",
      " |  positive : bool, optional\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update.  If int, random_state is the seed used by the random\n",
      " |      number generator; If RandomState instance, random_state is the random\n",
      " |      number generator; If None, the random number generator is the\n",
      " |      RandomState instance used by `np.random`. Used when ``selection`` ==\n",
      " |      'random'.\n",
      " |  \n",
      " |  selection : str, default 'cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features,) | (n_targets, n_features)\n",
      " |      parameter vector (w in the cost function formula)\n",
      " |  \n",
      " |  sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)\n",
      " |      ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
      " |  \n",
      " |  intercept_ : float | array, shape (n_targets,)\n",
      " |      independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : int | array-like, shape (n_targets,)\n",
      " |      number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import linear_model\n",
      " |  >>> clf = linear_model.Lasso(alpha=0.1)\n",
      " |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      " |  Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      " |     normalize=False, positive=False, precompute=False, random_state=None,\n",
      " |     selection='cyclic', tol=0.0001, warm_start=False)\n",
      " |  >>> print(clf.coef_)\n",
      " |  [ 0.85  0.  ]\n",
      " |  >>> print(clf.intercept_)\n",
      " |  0.15\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  lars_path\n",
      " |  lasso_path\n",
      " |  LassoLars\n",
      " |  LassoCV\n",
      " |  LassoLarsCV\n",
      " |  sklearn.decomposition.sparse_encode\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The algorithm used to fit the model is coordinate descent.\n",
      " |  \n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Lasso\n",
      " |      ElasticNet\n",
      " |      sklearn.linear_model.base.LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like}, shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          Target values\n",
      " |      \n",
      " |      l1_ratio : float, optional\n",
      " |          float between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso\n",
      " |      \n",
      " |      eps : float\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``\n",
      " |      \n",
      " |      n_alphas : int, optional\n",
      " |          Number of alphas along the regularization path\n",
      " |      \n",
      " |      alphas : ndarray, optional\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically\n",
      " |      \n",
      " |      precompute : True | False | 'auto' | array-like\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like, optional\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : boolean, optional, default True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : array, shape (n_features, ) | None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or integer\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      return_n_iter : bool\n",
      " |          whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |      \n",
      " |      check_input : bool, default True\n",
      " |          Skip input validation checks, including the Gram matrix when provided\n",
      " |          assuming there are handled by the caller when check_input=False.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : array, shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : array, shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : array-like, shape (n_alphas,)\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet\n",
      " |      MultiTaskElasticNetCV\n",
      " |      ElasticNet\n",
      " |      ElasticNetCV\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ElasticNet:\n",
      " |  \n",
      " |  fit(self, X, y, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : ndarray or scipy.sparse matrix, (n_samples, n_features)\n",
      " |          Data\n",
      " |      \n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ElasticNet:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      sparse representation of the fitted ``coef_``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (string) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : string, callable, list/tuple, dict or None, default: None\n",
      " |      A single string (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's default scorer (if available) is used.\n",
      " |  \n",
      " |  fit_params : dict, optional\n",
      " |      Parameters to pass to the fit method.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``fit_params`` as a constructor argument was deprecated in version\n",
      " |         0.19 and will be removed in version 0.21. Pass fit parameters to\n",
      " |         the ``fit`` method instead.\n",
      " |  \n",
      " |  n_jobs : int, default=1\n",
      " |      Number of jobs to run in parallel.\n",
      " |  \n",
      " |  pre_dispatch : int, or string, optional\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A string, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : boolean, default=True\n",
      " |      If True, the data is assumed to be identically distributed across\n",
      " |      the folds, and the loss minimized is the total loss per sample,\n",
      " |      and not the mean loss across the folds.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |        - None, to use the default 3-fold cross validation,\n",
      " |        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |        - An object to be used as a cross-validation generator.\n",
      " |        - An iterable yielding train, test splits.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |  refit : boolean, or string, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a string denoting the\n",
      " |      scorer is used to find the best parameters for refitting the estimator\n",
      " |      at the end.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_parameters_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' (default) or numeric\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : boolean, optional\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |  \n",
      " |      Current default is ``'warn'``, which behaves as ``True`` in addition\n",
      " |      to raising a warning when a training score is looked up.\n",
      " |      That default will be changed to ``False`` in 0.21.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  GridSearchCV(cv=None, error_score=...,\n",
      " |         estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n",
      " |                       decision_function_shape='ovr', degree=..., gamma=...,\n",
      " |                       kernel='rbf', max_iter=-1, probability=False,\n",
      " |                       random_state=None, shrinking=True, tol=...,\n",
      " |                       verbose=False),\n",
      " |         fit_params=None, iid=..., n_jobs=1,\n",
      " |         param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\n",
      " |         scoring=..., verbose=...)\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'mean_train_score', 'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split0_train_score', 'split1_test_score', 'split1_train_score',...\n",
      " |   'split2_test_score', 'split2_train_score',...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score', 'std_train_score'...]\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |        0.8      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |        0.7      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |        0.8      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |        0.9      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.8, 0.7, 0.8, 0.9],\n",
      " |          'split1_test_score'  : [0.82, 0.5, 0.7, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.82],\n",
      " |          'std_test_score'     : [0.02, 0.01, 0.03, 0.03],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.8, 0.9, 0.7],\n",
      " |          'split1_train_score' : [0.82, 0.5, 0.7],\n",
      " |          'mean_train_score'   : [0.81, 0.7, 0.7],\n",
      " |          'std_train_score'    : [0.03, 0.03, 0.04],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.001, 0.002, 0.003, 0.005],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator or dict\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score='raise', return_train_score='warn')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  grid_scores_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'alpha': [0.01, 0.1, 1]}\n",
    "ridge = Ridge()\n",
    "clf = GridSearchCV(ridge, params, cv=2, scoring = 'neg_mean_squared_error') # mean_squared_error\n",
    "clf.fit(X_train[['HoursStudied']],y_train)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00436902, 0.00127208, 0.00094962]), 'std_fit_time': array([3.14402580e-03, 2.41875648e-04, 2.74181366e-05]), 'mean_score_time': array([0.00036848, 0.00026667, 0.00023794]), 'std_score_time': array([1.23620033e-04, 1.87158585e-05, 1.19209290e-06]), 'param_alpha': masked_array(data=[0.01, 0.1, 1],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}], 'split0_test_score': array([-375.44861314, -375.44844083, -375.44671936]), 'split1_test_score': array([-349.32881057, -349.32893766, -349.33020856]), 'mean_test_score': array([-362.53545232, -362.53542802, -362.53518593]), 'std_test_score': array([13.05907688, 13.05892718, 13.05743109]), 'rank_test_score': array([3, 2, 1], dtype=int32), 'split0_train_score': array([-325.05753132, -325.05753133, -325.05753231]), 'split1_train_score': array([-351.57383869, -351.57383869, -351.57383906]), 'mean_train_score': array([-338.315685  , -338.31568501, -338.31568569]), 'std_train_score': array([13.25815368, 13.25815368, 13.25815338])}\n"
     ]
    }
   ],
   "source": [
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Math,Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients/weights in linear_regression. #Source ml-cheatshet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the 3-dimensional graph below in the context of a cost function. Our goal is to move from the mountain in the top right corner (high cost) to the dark blue sea in the bottom left (low cost). The arrows represent the direction of steepest descent (negative gradient) from any given point--the direction that decreases the cost function as quickly as possible. \n",
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"fig/gradient_descent.png\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting at the top of the mountain, we take our first step downhill in the direction specified by the negative gradient. Next we recalculate the negative gradient (passing in the coordinates of our new point) and take another step in the direction it specifies. We continue this process iteratively until we get to the bottom of our graph, or to a point where we can no longer move downhill--a local minimum.\n",
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"fig/gradient_descent_demystified.png\">\n",
    "  </center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate\n",
    "The size of these steps is called the learning rate. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. With a very low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. A low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function: A cost_function tells us \"how good\" our model is at making predictions for a given set of parameters. The cost function has its own curve and its own gradients. The slope of this curve tells us how to update our parameters to make the model more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-by-step\n",
    "Now let's run gradient descent using our new cost function. There are two parameters in our cost function we can control: m (weight) and b (bias). Since we need to consider the impact each one has on the final prediction, we need to use partial derivatives. We calculate the partial derivatives of the cost function with respect to each parameter and store the results in a gradient.\n",
    "\n",
    "Math\n",
    "\n",
    "Given the cost function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align*}\n",
       "f(m,b) =  \\frac{1}{N} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r'''\n",
    "\\begin{align*}\n",
    "f(m,b) =  \\frac{1}{N} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2\n",
    "\\end{align*}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align*}\n",
       "f'(m,b) =\n",
       "   \\begin{bmatrix}\n",
       "     \\frac{df}{dm}\\\\\n",
       "     \\frac{df}{db}\\\\\n",
       "    \\end{bmatrix}\n",
       "=\n",
       "   \\begin{bmatrix}\n",
       "     \\frac{1}{N} \\sum -2x_i(y_i - (mx_i + b)) \\\\\n",
       "     \\frac{1}{N} \\sum -2(y_i - (mx_i + b)) \\\\\n",
       "    \\end{bmatrix}\n",
       "\\end{align*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(r'''\n",
    "\\begin{align*}\n",
    "f'(m,b) =\n",
    "   \\begin{bmatrix}\n",
    "     \\frac{df}{dm}\\\\\n",
    "     \\frac{df}{db}\\\\\n",
    "    \\end{bmatrix}\n",
    "=\n",
    "   \\begin{bmatrix}\n",
    "     \\frac{1}{N} \\sum -2x_i(y_i - (mx_i + b)) \\\\\n",
    "     \\frac{1}{N} \\sum -2(y_i - (mx_i + b)) \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve for the gradient, we iterate through our data points using our new m and b values and compute the partial derivatives. This new gradient tells us the slope of our cost function at our current position (current parameter values) and the direction we should move to update our parameters. The size of our update is controlled by the learning rate.\n",
    "\n",
    "Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(m, b, X, Y, learning_rate):\n",
    "    m_deriv = 0\n",
    "    b_deriv = 0\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        # Calculate partial derivatives\n",
    "        # -2x(y - (mx + b))\n",
    "        m_deriv += -2*X[i] * (Y[i] - (m*X[i] + b))\n",
    "\n",
    "        # -2(y - (mx + b))\n",
    "        b_deriv += -2*(Y[i] - (m*X[i] + b))\n",
    "\n",
    "    # We subtract because the derivatives point in direction of steepest ascent\n",
    "    m -= (m_deriv / float(N)) * learning_rate\n",
    "    b -= (b_deriv / float(N)) * learning_rate\n",
    "\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
